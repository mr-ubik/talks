<!-- classes: tf1-bg -->

<footer>
    <a class="alignright" href="https://twitter.com/mr_ubik"><i class="fab fa-twitter"></i> mr_ubik</a>
</footer>

---

### Phenomenal Computational powers ...

- `Python` crust with a creamy `C++` core
- Amazing performance
- Easy to deploy in production, especially at massive Google-like scale
- Static Graph meant you could code your model in Python and then export it as proto<br />
object to work with whatever language you wanted
- Highly performant input pipelines inside `tf.data`

<footer class="bg-white">
    <a class="alignright" href="https://twitter.com/mr_ubik"><i class="fab fa-twitter"></i> mr_ubik</a>
</footer>

----

### Ugly, Clunky API


However, for all its capabilities, it is a matter of fact that TF 1.X came very short in terms of API design and usability.

- Unclear API littered with redundancy and an exploding mess in terms of the `tf.contrib` module.
- The use of **Statically Defined Computational Graph** meant that the way to think about the graph was _Define and Run_<br />
in contrast to later fwameworks implementintga **Dynamically Defined Graph** such  as PyTorch.
- The explicit need to use Graph dependent scopes and variables which clashed with the concept of Pythonic code.<br />
These objects did not behave as normal Python objects and thus required to familiarity to work with them.

<footer class="bg-white">
    <a class="alignright" href="https://twitter.com/mr_ubik"><i class="fab fa-twitter"></i> mr_ubik</a>
</footer>

---

<!-- classes: anon -->

```
> Be a Machine Learning
> Working with TensorFlow required rethinking your coding habits
> Obstacles during the debugging + required adaptation = Slow Develepment for newcomers
> Plenty of newcomers due to the ML Craze
> Most pepole (i.e., researchers) were not leveraging the production capabilities of the framework
> PyTorch comes along lighting a fire under TF comfy position as the ONE FRAMEWORK by covering all the usability issues
while offering a performant eager computation (production deployment of the models was,
and still is in my opinion inferior in terms of easiness and raw performance to TF, but PyTorch is quickly gaining ground)
> People, especially in the academia start migrating towards it
> You start thinking about refatcoring everything to PyTorch
> You panic
> You vomit
> You cry yourself to sleep
> Decide to wait
> You wait some more
> Summer 2018 comes, you try TF Eager Mode but no banana
> PyTorch 1.0 releases
> You go over the panic cycle again
> You wait another while
> Competition does its magic and TF starts shifting to meet its user base
> Now you maybe don't need to learn two frameworks
```
